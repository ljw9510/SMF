{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our **Y_test**, whose size is $3 \\times 3$,\n",
    "$$ \n",
    "Y_\\text{test} = \\begin{bmatrix} 0 & 0 & 0 \\\\\n",
    " 0 & 1 &  0\\\\\n",
    "  0 & 0& 1 \\end{bmatrix}\n",
    "$$\n",
    "Columns are different samples. In each column(sample), if $i$ th row is 1, then this sample belongs to $i$ th class. If all 0, then it is in class 0. So, row dimension is $k-1$ , where $k$ is the class number.\n",
    "\n",
    "For **P_pred**, after my modification, its input should be size $4 \\times 3$. Each column still represents each sample. Now, the $i$ th row indicates the probability that this sample is from class $i$. So, in each column, if you sum up all entries, the result is 1. \n",
    "\n",
    "In previous function **validation_multi**, I add a line (Please see the code below). This line of code stack an all 1 row vector at the top of original **P_pred**, which is represent the probability of sample classified into class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The first function I modified:\n",
    "# ! Don't run this code. Just want to show what I have modified.\n",
    "\n",
    "# In class: SMF_BCD\n",
    "def validation_multi(self,\n",
    "                         threshold = 0.5, \n",
    "                    result_dict=None,\n",
    "                    X_test = None,\n",
    "                    X_test_aux = None,\n",
    "                    sub_iter=100,\n",
    "                    verbose=False,\n",
    "                    stopping_grad_ratio=0.0001,\n",
    "                    prediction_method_list = ['filter', 'naive', 'alt', 'exhaustive']):\n",
    "        '''\n",
    "        Given input X = [data, label] and initial loading dictionary W_ini, find W = [dict, beta] and code H\n",
    "        by two-block coordinate descent: [dict, beta] --> H, H--> [dict, beta]\n",
    "        Use Logistic MF model\n",
    "        '''\n",
    "        if result_dict is None:\n",
    "            result_dict = self.result_dict\n",
    "        if X_test is None:\n",
    "            X_test = self.X_test\n",
    "        if X_test_aux is None:\n",
    "            X_test_aux = self.X_test_aux\n",
    "\n",
    "        test_X = X_test[0]\n",
    "        test_Y = X_test[1]\n",
    "\n",
    "        W = result_dict.get('loading')\n",
    "        beta = W[1].T\n",
    "        \n",
    "        for pred_type in prediction_method_list:\n",
    "            print('!!! pred_type', pred_type)\n",
    "            if pred_type == 'filter':\n",
    "                X0_comp = W[0].T @ X_test[0]\n",
    "                X0_ext = np.vstack((np.ones(X_test[1].shape[1]), X0_comp))\n",
    "                if self.d3>0:\n",
    "                    X0_ext = np.vstack((X0_ext, X_test_aux))\n",
    "                exp_numerator = np.matmul(W[1], X0_ext)\n",
    "                exp_numerator = np.exp(exp_numerator)\n",
    "                normalizer = np.zeros(X_test[0].shape[1])\n",
    "                for i in range(len(normalizer)):\n",
    "                    normalizer[i] = 1 + np.sum(exp_numerator[:, i])\n",
    "                P_pred = np.copy(exp_numerator)\n",
    "\n",
    "                ################ Only need to add the line below !!!!!!!!!!!!   \n",
    "                P_pred = np.vstack((np.ones(P_pred.shape[1]),P_pred))    # this line  !!!!!!!!!\n",
    "                ################ Only need to add the line above !!!!!!!!!!!! \n",
    "                  \n",
    "                for i in range(X_test[0].shape[1]):\n",
    "                    P_pred[:, i] = P_pred[:, i] / normalizer[i]\n",
    "                \n",
    "                accuracy_result = multiclass_accuracy_metrics(Y_test=self.X_test[1], \n",
    "                                                            P_pred=P_pred, threshold=threshold)\n",
    "                if verbose == True:\n",
    "                    confusion_matrix = accuracy_result.get('confusion_mx')\n",
    "                    ACC = accuracy_result.get('Accuracy')\n",
    "                    print('!!! --- Validation --- [confusion_mx, Accuracy] = ', [confusion_matrix, np.round(ACC, 3)])\n",
    "        return accuracy_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The second function I modified:\n",
    "# Please run this code to do tests\n",
    "\n",
    "def multiclass_accuracy_metrics(Y_test, P_pred, result_dict, threshold = 0.5, class_labels=None, use_opt_threshold=False):\n",
    "    '''\n",
    "    y_test = multiclass one-hot encoding  labels \n",
    "    Q = predicted probability for y_test\n",
    "    compuate various classification accuracy metrics\n",
    "    '''\n",
    "\n",
    "    # k: number of classes, n: number of samples\n",
    "    # Y_test: (k-1) by n\n",
    "    # P_Pred: k by n\n",
    "\n",
    "    Y_test_T = Y_test.T\n",
    "    P_pred_T = P_pred.T\n",
    "    results_dict = {}\n",
    "\n",
    "    count = 0\n",
    "    for i in np.arange(Y_test_T.shape[0]):\n",
    "        # Get the predicted class of sample \"i\" as a number: y1\n",
    "        y1 = np.arange(P_pred_T.shape[1])[np.max(P_pred_T[i,:]) ==  P_pred_T[i,:]][0]\n",
    "        \n",
    "        # Get the true class of sample \"i\" as a number: y2\n",
    "        if np.max(Y_test_T[i,:]) == 1:\n",
    "            y2 = np.sum( np.arange(1,Y_test_T.shape[1]+1) * (Y_test_T[i,:] == 1) )\n",
    "        else:\n",
    "            y2 = 0 \n",
    "        \n",
    "        if np.abs(y1-y2) < 1e-4: # Compare result\n",
    "            count = count + 1 # count correctly classified samples\n",
    "        \n",
    "    accuracy = count / Y_test_T.shape[0] \n",
    "\n",
    "    results_dict.update({'Accuracy': accuracy})\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "Y_test = np.array([[0,0,0],\n",
    "                   [0,1,0],\n",
    "                   [0,0,1]])\n",
    "\n",
    "### Below is our !!! function input P_pred !!!\n",
    "P_pred = np.array([[0.9 ,0.2 ,0.1],\n",
    "                   [0.01,0.27,0.2],\n",
    "                   [0.02,0.23,0.4],\n",
    "                   [0.07,0.3 ,0.3]])\n",
    "\n",
    "# If you convert this P_pred into the format of Y_test,\n",
    "    # Y_pred=\n",
    "    # 0   0   0\n",
    "    # 0   0   1\n",
    "    # 0   1   0\n",
    "# In this test example, accuracy = 1/3\n",
    "\n",
    "result_dict = {}\n",
    "result_dict.update({'Accuracy': np.array([0])})\n",
    "\n",
    "result_dict = multiclass_accuracy_metrics(Y_test=Y_test, P_pred=P_pred, result_dict=result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict.get('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
